{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f4e36302",
   "metadata": {},
   "source": [
    "<h2 align='center'>Codebasics ML Course: ML Flow Tutorial</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "295e5486",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ac73cd36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1]), array([900, 100]))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 1: Create an imbalanced binary classification dataset\n",
    "X, y = make_classification(n_samples=1000, n_features=10, n_informative=2, n_redundant=8, \n",
    "                           weights=[0.9, 0.1], flip_y=0, random_state=42)\n",
    "\n",
    "np.unique(y, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0934ac03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, stratify=y, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "027f7e0a",
   "metadata": {},
   "source": [
    "### Experiment 1: Train Logistic Regression Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "df52d46a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.96      0.95       270\n",
      "           1       0.60      0.50      0.55        30\n",
      "\n",
      "    accuracy                           0.92       300\n",
      "   macro avg       0.77      0.73      0.75       300\n",
      "weighted avg       0.91      0.92      0.91       300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "log_reg = LogisticRegression(C=1, solver='liblinear')\n",
    "log_reg.fit(X_train, y_train)\n",
    "y_pred_log_reg = log_reg.predict(X_test)\n",
    "print(classification_report(y_test, y_pred_log_reg))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1468bab4",
   "metadata": {},
   "source": [
    "### Experiment 2: Train Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2742e30d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98       270\n",
      "           1       0.95      0.67      0.78        30\n",
      "\n",
      "    accuracy                           0.96       300\n",
      "   macro avg       0.96      0.83      0.88       300\n",
      "weighted avg       0.96      0.96      0.96       300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf_clf = RandomForestClassifier(n_estimators=30, max_depth=3)\n",
    "rf_clf.fit(X_train, y_train)\n",
    "y_pred_rf = rf_clf.predict(X_test)\n",
    "print(classification_report(y_test, y_pred_rf))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7db18915",
   "metadata": {},
   "source": [
    "### Experiment 3: Train XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fa3fe3e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99       270\n",
      "           1       0.96      0.80      0.87        30\n",
      "\n",
      "    accuracy                           0.98       300\n",
      "   macro avg       0.97      0.90      0.93       300\n",
      "weighted avg       0.98      0.98      0.98       300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "xgb_clf = XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n",
    "xgb_clf.fit(X_train, y_train)\n",
    "y_pred_xgb = xgb_clf.predict(X_test)\n",
    "print(classification_report(y_test, y_pred_xgb))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b70bbef1",
   "metadata": {},
   "source": [
    "### Experiment 4: Handle class imbalance using SMOTETomek and then Train XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e74541df-c7d4-4f10-96ce-80c9d051eef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.neighbors import KDTree\n",
    "\n",
    "class SMOTETomek_like:\n",
    "    def __init__(self, random_state=42, k_neighbors=5, remove_tomek=True, target_count=None):\n",
    "        \"\"\"\n",
    "        SMOTE + Tomek links combination, mimicking imbalanced-learn SMOTETomek.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        random_state : int\n",
    "            Seed for reproducibility.\n",
    "        k_neighbors : int\n",
    "            Number of nearest neighbors for SMOTE.\n",
    "        remove_tomek : bool\n",
    "            Whether to remove Tomek links after SMOTE.\n",
    "        target_count : int or None\n",
    "            If int, upsample all classes to exactly this number of samples.\n",
    "            If None, upsample to the original majority class.\n",
    "        \"\"\"\n",
    "        self.random_state = random_state\n",
    "        self.k_neighbors = k_neighbors\n",
    "        self.remove_tomek = remove_tomek\n",
    "        self.target_count = target_count\n",
    "\n",
    "    def fit_resample(self, X, y):\n",
    "        np.random.seed(self.random_state)\n",
    "        X = np.asarray(X)\n",
    "        y = np.asarray(y)\n",
    "\n",
    "        # --- Step 1: SMOTE ---\n",
    "        classes, counts = np.unique(y, return_counts=True)\n",
    "\n",
    "        if self.target_count is None:\n",
    "            majority_count = max(counts)\n",
    "        else:\n",
    "            majority_count = self.target_count\n",
    "\n",
    "        X_res_list = []\n",
    "        y_res_list = []\n",
    "\n",
    "        for cls in classes:\n",
    "            X_cls = X[y == cls]\n",
    "            n_cls = len(X_cls)\n",
    "            X_res_list.append(X_cls)\n",
    "            y_res_list.append(np.full(n_cls, cls))\n",
    "\n",
    "            if n_cls < majority_count:\n",
    "                n_to_generate = majority_count - n_cls\n",
    "                k = min(self.k_neighbors, n_cls)\n",
    "                tree = KDTree(X_cls)\n",
    "                synthetic_samples = []\n",
    "\n",
    "                for _ in range(n_to_generate):\n",
    "                    idx = np.random.randint(0, n_cls)\n",
    "                    x = X_cls[idx]\n",
    "                    nn_idx = tree.query([x], k=k, return_distance=False)[0]\n",
    "                    neighbor = X_cls[np.random.choice(nn_idx)]\n",
    "                    synthetic = x + np.random.rand() * (neighbor - x)\n",
    "                    synthetic_samples.append(synthetic)\n",
    "\n",
    "                X_res_list.append(np.array(synthetic_samples))\n",
    "                y_res_list.append(np.full(n_to_generate, cls))\n",
    "\n",
    "        X_res = np.vstack(X_res_list)\n",
    "        y_res = np.hstack(y_res_list)\n",
    "\n",
    "        # --- Step 2: Optional Tomek links removal ---\n",
    "        if self.remove_tomek:\n",
    "            X_res, y_res = self._remove_tomek_links(X_res, y_res, target_count=majority_count)\n",
    "\n",
    "        return X_res, y_res\n",
    "\n",
    "    def _remove_tomek_links(self, X, y, target_count):\n",
    "        \"\"\"\n",
    "        Remove majority samples forming Tomek links, but never reduce\n",
    "        any class below the target_count.\n",
    "        \"\"\"\n",
    "        classes = np.unique(y)\n",
    "        X_clean_list = []\n",
    "        y_clean_list = []\n",
    "\n",
    "        # Start with all samples\n",
    "        X_remaining = X.copy()\n",
    "        y_remaining = y.copy()\n",
    "\n",
    "        for cls in classes:\n",
    "            X_cls = X_remaining[y_remaining == cls]\n",
    "            y_cls = y_remaining[y_remaining == cls]\n",
    "\n",
    "            for other_cls in classes:\n",
    "                if cls == other_cls:\n",
    "                    continue\n",
    "                X_other = X_remaining[y_remaining == other_cls]\n",
    "                y_other = y_remaining[y_remaining == other_cls]\n",
    "\n",
    "                if len(X_other) == 0 or len(X_cls) == 0:\n",
    "                    continue\n",
    "\n",
    "                tree_cls = KDTree(X_cls)\n",
    "                tree_other = KDTree(X_other)\n",
    "\n",
    "                dist_other, idx_other = tree_cls.query(X_other, k=1)\n",
    "                dist_cls, idx_cls = tree_other.query(X_cls, k=1)\n",
    "\n",
    "                mask_other = np.ones(len(X_other), dtype=bool)\n",
    "                for i, j in enumerate(idx_other[:, 0]):\n",
    "                    if idx_cls[j, 0] == i:\n",
    "                        # Remove sample only if class count remains >= target_count\n",
    "                        if len(X_other[mask_other]) > target_count:\n",
    "                            mask_other[i] = False\n",
    "\n",
    "                X_other_clean = X_other[mask_other]\n",
    "                y_other_clean = y_other[mask_other]\n",
    "\n",
    "                # Add cleaned samples\n",
    "                X_clean_list.append(X_cls)\n",
    "                y_clean_list.append(y_cls)\n",
    "                X_clean_list.append(X_other_clean)\n",
    "                y_clean_list.append(y_other_clean)\n",
    "\n",
    "                # Update remaining samples\n",
    "                X_remaining = np.vstack([X_cls, X_other_clean])\n",
    "                y_remaining = np.hstack([y_cls, y_other_clean])\n",
    "\n",
    "        X_final = np.vstack(X_clean_list)\n",
    "        y_final = np.hstack(y_clean_list)\n",
    "\n",
    "        # --- Step 3: Trim any excess if necessary to match exact target_count ---\n",
    "        X_trimmed_list = []\n",
    "        y_trimmed_list = []\n",
    "        for cls in np.unique(y_final):\n",
    "            X_cls = X_final[y_final == cls]\n",
    "            y_cls = y_final[y_final == cls]\n",
    "            if len(X_cls) > target_count:\n",
    "                idx_keep = np.random.choice(len(X_cls), target_count, replace=False)\n",
    "                X_cls = X_cls[idx_keep]\n",
    "                y_cls = y_cls[idx_keep]\n",
    "            X_trimmed_list.append(X_cls)\n",
    "            y_trimmed_list.append(y_cls)\n",
    "\n",
    "        X_final = np.vstack(X_trimmed_list)\n",
    "        y_final = np.hstack(y_trimmed_list)\n",
    "\n",
    "        return X_final, y_final\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5ecbe6a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1]), array([619, 619]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from imblearn.combine import SMOTETomek\n",
    "\n",
    "# smt = SMOTETomek(random_state=42)\n",
    "# X_train_res, y_train_res = smt.fit_resample(X_train, y_train)\n",
    "\n",
    "# np.unique(y_train_res, return_counts=True)\n",
    "\n",
    "# --- Step 1: Create instance ---\n",
    "desired_count = 619  # exact number of samples per class\n",
    "smt_like = SMOTETomek_like(\n",
    "    random_state=42,\n",
    "    k_neighbors=5,\n",
    "    remove_tomek=True,\n",
    "    target_count=desired_count\n",
    ")\n",
    "\n",
    "# --- Step 2: Resample training data ---\n",
    "X_train_res, y_train_res = smt_like.fit_resample(X_train, y_train)\n",
    "\n",
    "# --- Step 3: Check the class distribution ---\n",
    "np.unique(y_train_res, return_counts=True)\n",
    "# Expected output: (array([0, 1]), array([619, 619]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2b931191",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.94      0.96       270\n",
      "           1       0.62      0.83      0.71        30\n",
      "\n",
      "    accuracy                           0.93       300\n",
      "   macro avg       0.80      0.89      0.84       300\n",
      "weighted avg       0.95      0.93      0.94       300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "xgb_clf = XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n",
    "xgb_clf.fit(X_train_res, y_train_res)\n",
    "y_pred_xgb = xgb_clf.predict(X_test)\n",
    "print(classification_report(y_test, y_pred_xgb))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ac546b4",
   "metadata": {},
   "source": [
    "<h2 align=\"center\" style=\"color:blue\">Track Experiments Using MLFlow</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9fc788a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    (\n",
    "        \"Logistic Regression\", \n",
    "        {\"C\": 1, \"solver\": 'liblinear'},\n",
    "        LogisticRegression(), \n",
    "        (X_train, y_train),\n",
    "        (X_test, y_test)\n",
    "    ),\n",
    "    (\n",
    "        \"Random Forest\", \n",
    "        {\"n_estimators\": 30, \"max_depth\": 3},\n",
    "        RandomForestClassifier(), \n",
    "        (X_train, y_train),\n",
    "        (X_test, y_test)\n",
    "    ),\n",
    "    (\n",
    "        \"XGBClassifier\",\n",
    "        {\"use_label_encoder\": False, \"eval_metric\": 'logloss'},\n",
    "        XGBClassifier(), \n",
    "        (X_train, y_train),\n",
    "        (X_test, y_test)\n",
    "    ),\n",
    "    (\n",
    "        \"XGBClassifier With SMOTE\",\n",
    "        {\"use_label_encoder\": False, \"eval_metric\": 'logloss'},\n",
    "        XGBClassifier(), \n",
    "        (X_train_res, y_train_res),\n",
    "        (X_test, y_test)\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1a827a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "reports = []\n",
    "\n",
    "for model_name, params, model, train_set, test_set in models:\n",
    "    X_train = train_set[0]\n",
    "    y_train = train_set[1]\n",
    "    X_test = test_set[0]\n",
    "    y_test = test_set[1]\n",
    "    \n",
    "    model.set_params(**params)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    report = classification_report(y_test, y_pred, output_dict=True)\n",
    "    reports.append(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bfd15560-113b-4519-a2be-74610cbfc506",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'0': {'precision': 0.9454545454545454,\n",
       "   'recall': 0.9629629629629629,\n",
       "   'f1-score': 0.9541284403669725,\n",
       "   'support': 270.0},\n",
       "  '1': {'precision': 0.6,\n",
       "   'recall': 0.5,\n",
       "   'f1-score': 0.5454545454545454,\n",
       "   'support': 30.0},\n",
       "  'accuracy': 0.9166666666666666,\n",
       "  'macro avg': {'precision': 0.7727272727272727,\n",
       "   'recall': 0.7314814814814814,\n",
       "   'f1-score': 0.749791492910759,\n",
       "   'support': 300.0},\n",
       "  'weighted avg': {'precision': 0.9109090909090909,\n",
       "   'recall': 0.9166666666666666,\n",
       "   'f1-score': 0.91326105087573,\n",
       "   'support': 300.0}},\n",
       " {'0': {'precision': 0.9676258992805755,\n",
       "   'recall': 0.9962962962962963,\n",
       "   'f1-score': 0.9817518248175182,\n",
       "   'support': 270.0},\n",
       "  '1': {'precision': 0.9545454545454546,\n",
       "   'recall': 0.7,\n",
       "   'f1-score': 0.8076923076923077,\n",
       "   'support': 30.0},\n",
       "  'accuracy': 0.9666666666666667,\n",
       "  'macro avg': {'precision': 0.961085676913015,\n",
       "   'recall': 0.8481481481481481,\n",
       "   'f1-score': 0.8947220662549129,\n",
       "   'support': 300.0},\n",
       "  'weighted avg': {'precision': 0.9663178548070633,\n",
       "   'recall': 0.9666666666666667,\n",
       "   'f1-score': 0.9643458731049971,\n",
       "   'support': 300.0}},\n",
       " {'0': {'precision': 0.9781818181818182,\n",
       "   'recall': 0.9962962962962963,\n",
       "   'f1-score': 0.9871559633027523,\n",
       "   'support': 270.0},\n",
       "  '1': {'precision': 0.96,\n",
       "   'recall': 0.8,\n",
       "   'f1-score': 0.8727272727272727,\n",
       "   'support': 30.0},\n",
       "  'accuracy': 0.9766666666666667,\n",
       "  'macro avg': {'precision': 0.969090909090909,\n",
       "   'recall': 0.8981481481481481,\n",
       "   'f1-score': 0.9299416180150125,\n",
       "   'support': 300.0},\n",
       "  'weighted avg': {'precision': 0.9763636363636364,\n",
       "   'recall': 0.9766666666666667,\n",
       "   'f1-score': 0.9757130942452044,\n",
       "   'support': 300.0}},\n",
       " {'0': {'precision': 0.9807692307692307,\n",
       "   'recall': 0.9444444444444444,\n",
       "   'f1-score': 0.9622641509433962,\n",
       "   'support': 270.0},\n",
       "  '1': {'precision': 0.625,\n",
       "   'recall': 0.8333333333333334,\n",
       "   'f1-score': 0.7142857142857143,\n",
       "   'support': 30.0},\n",
       "  'accuracy': 0.9333333333333333,\n",
       "  'macro avg': {'precision': 0.8028846153846154,\n",
       "   'recall': 0.8888888888888888,\n",
       "   'f1-score': 0.8382749326145553,\n",
       "   'support': 300.0},\n",
       "  'weighted avg': {'precision': 0.9451923076923078,\n",
       "   'recall': 0.9333333333333333,\n",
       "   'f1-score': 0.937466307277628,\n",
       "   'support': 300.0}}]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "29ca91b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# Imports\n",
    "# =========================\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import mlflow.xgboost\n",
    "\n",
    "# from mlflow.tracking import MlflowClient\n",
    "from xgboost import XGBClassifier, XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "01a93bfa-3870-44f0-9011-5cbdd7831d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# Helper function to log models\n",
    "# =========================\n",
    "def log_model_with_mlflow(model, model_name: str):\n",
    "    \"\"\"\n",
    "    Safely log models to MLflow on Python 3.13.\n",
    "    - Uses mlflow.xgboost for XGBoost models\n",
    "    - Uses mlflow.sklearn for all other models\n",
    "    - Uses the new MLflow `name` parameter (no deprecation warnings)\n",
    "    \"\"\"\n",
    "\n",
    "    if \"XGB\" in model_name:\n",
    "        # Defensive estimator type patching\n",
    "        if not hasattr(model, \"_estimator_type\"):\n",
    "            if isinstance(model, XGBClassifier):\n",
    "                model._estimator_type = \"classifier\"\n",
    "            elif isinstance(model, XGBRegressor):\n",
    "                model._estimator_type = \"regressor\"\n",
    "            else:\n",
    "                model._estimator_type = \"classifier\"\n",
    "\n",
    "        mlflow.xgboost.log_model(\n",
    "            model,\n",
    "            name=\"model\",\n",
    "            pip_requirements=[\n",
    "                \"xgboost==3.1.2\",\n",
    "                \"scikit-learn\",\n",
    "                \"numpy\"\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    else:\n",
    "        mlflow.sklearn.log_model(\n",
    "            model,\n",
    "            name=\"model\",\n",
    "            pip_requirements=[\n",
    "                \"scikit-learn\",\n",
    "                \"numpy\"\n",
    "            ]\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "420f2511",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/12/25 15:59:52 INFO mlflow.tracking.fluent: Experiment with name 'Anomaly Detection' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run Logistic Regression at: http://localhost:5000/#/experiments/1/runs/e139d36b0e764b249328dd575f4e93eb\n",
      "üß™ View experiment at: http://localhost:5000/#/experiments/1\n",
      "üèÉ View run Random Forest at: http://localhost:5000/#/experiments/1/runs/db0c943a4bdd458eab596e2ea9fb0ad0\n",
      "üß™ View experiment at: http://localhost:5000/#/experiments/1\n",
      "üèÉ View run XGBClassifier at: http://localhost:5000/#/experiments/1/runs/29e5335215cb4b618419af136a17fc23\n",
      "üß™ View experiment at: http://localhost:5000/#/experiments/1\n",
      "üèÉ View run XGBClassifier With SMOTE at: http://localhost:5000/#/experiments/1/runs/640aa0b1aea4450f84eff29b8e1ad6cd\n",
      "üß™ View experiment at: http://localhost:5000/#/experiments/1\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# MLflow Initialization (DEFENSIVE)\n",
    "# =========================\n",
    "# mlflow.set_tracking_uri(\"http://localhost:5000\")\n",
    "\n",
    "# client = MlflowClient()\n",
    "# experiment_name = \"Anomaly Detection\"\n",
    "\n",
    "# exp = client.get_experiment_by_name(experiment_name)\n",
    "\n",
    "# if exp and exp.lifecycle_stage == \"deleted\":\n",
    "    # client.restore_experiment(exp.experiment_id)\n",
    "\n",
    "# mlflow.set_experiment(experiment_name)\n",
    "\n",
    "# 1. Set tracking server FIRST\n",
    "mlflow.set_tracking_uri(\"http://localhost:5000\")\n",
    "\n",
    "# 2. Then set / create experiment\n",
    "mlflow.set_experiment(\"Anomaly Detection\")\n",
    "\n",
    "\n",
    "# =========================\n",
    "# Training / Logging Loop\n",
    "# =========================\n",
    "for i, element in enumerate(models):\n",
    "    model_name = element[0]\n",
    "    params = element[1]\n",
    "    model = element[2]\n",
    "    report = reports[i]\n",
    "\n",
    "    with mlflow.start_run(run_name=model_name):\n",
    "        mlflow.log_params(params)\n",
    "\n",
    "        mlflow.log_metrics({\n",
    "            \"accuracy\": report[\"accuracy\"],\n",
    "            \"recall_class_1\": report[\"1\"][\"recall\"],\n",
    "            \"recall_class_0\": report[\"0\"][\"recall\"],\n",
    "            \"f1_score_macro\": report[\"macro avg\"][\"f1-score\"]\n",
    "        })\n",
    "\n",
    "        log_model_with_mlflow(model, model_name)\n",
    "\n",
    "# =========================\n",
    "# End of MLflow logging\n",
    "# ========================="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6c648d9-f04c-470c-930f-57b168fd298c",
   "metadata": {},
   "source": [
    "### Register the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fa24a529-a6ff-442d-8d73-3d15a22f8c17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Please type RunID:  640aa0b1aea4450f84eff29b8e1ad6cd\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Successfully registered model 'XGB-Smote'.\n",
      "2025/12/25 16:02:22 WARNING mlflow.tracking._model_registry.fluent: Run with id 640aa0b1aea4450f84eff29b8e1ad6cd has no artifacts at artifact path 'model', registering model based on models:/m-298ec5bf10fc41458a31cf34d1f4abe1 instead\n",
      "2025/12/25 16:02:22 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: XGB-Smote, version 1\n",
      "Created version '1' of model 'XGB-Smote'.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<ModelVersion: aliases=[], creation_timestamp=1766671342474, current_stage='None', deployment_job_state=<ModelVersionDeploymentJobState: current_task_name='', job_id='', job_state='DEPLOYMENT_JOB_CONNECTION_STATE_UNSPECIFIED', run_id='', run_state='DEPLOYMENT_JOB_RUN_STATE_UNSPECIFIED'>, description='', last_updated_timestamp=1766671342474, metrics=None, model_id=None, name='XGB-Smote', params=None, run_id='640aa0b1aea4450f84eff29b8e1ad6cd', run_link='', source='models:/m-298ec5bf10fc41458a31cf34d1f4abe1', status='READY', status_message=None, tags={}, user_id='', version='1'>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import mlflow\n",
    "\n",
    "model_name = \"XGB-Smote\"\n",
    "run_id = input(\"Please type RunID: \").strip()\n",
    "\n",
    "# IMPORTANT: this must match the artifact path used when the model was logged\n",
    "artifact_path = \"model\"\n",
    "\n",
    "model_uri = f\"runs:/{run_id}/{artifact_path}\"\n",
    "\n",
    "# You do NOT need to reopen the run\n",
    "mlflow.register_model(\n",
    "    model_uri=model_uri,\n",
    "    name=model_name\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e9e1d0f-c03d-4d68-be1d-46b4ba9b956a",
   "metadata": {},
   "source": [
    "### Load the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "47021085-6471-4827-b283-567efa710c7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Local MLflow model path: C:\\Users\\GGL\\AppData\\Local\\Temp\\tmp7eedxrid\\\n",
      "C:\\Users\\GGL\\AppData\\Local\\Temp\\tmp7eedxrid\\conda.yaml\n",
      "C:\\Users\\GGL\\AppData\\Local\\Temp\\tmp7eedxrid\\MLmodel\n",
      "C:\\Users\\GGL\\AppData\\Local\\Temp\\tmp7eedxrid\\model.ubj\n",
      "C:\\Users\\GGL\\AppData\\Local\\Temp\\tmp7eedxrid\\python_env.yaml\n",
      "C:\\Users\\GGL\\AppData\\Local\\Temp\\tmp7eedxrid\\registered_model_meta\n",
      "C:\\Users\\GGL\\AppData\\Local\\Temp\\tmp7eedxrid\\requirements.txt\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "print(\"Local MLflow model path:\", local_path)\n",
    "\n",
    "for root, dirs, files in os.walk(local_path):\n",
    "    for name in files:\n",
    "        print(os.path.join(root, name))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "eb2f521c-d477-4f3e-b605-8abe2462e241",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19e8b591b25b419caf9555480eef586a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([0.00236887, 0.0019822 , 0.01328653, 0.000823  ], dtype=float32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import mlflow\n",
    "import xgboost as xgb\n",
    "import os\n",
    "\n",
    "# Download model artifacts\n",
    "local_path = mlflow.artifacts.download_artifacts(\n",
    "    artifact_uri=f\"models:/{model_name}@challenger\" # /{model_version}\n",
    ")\n",
    "\n",
    "# Correct model file (from inspection)\n",
    "model_file = os.path.join(local_path, \"model.ubj\")\n",
    "\n",
    "# Load raw XGBoost booster\n",
    "booster = xgb.Booster()\n",
    "booster.load_model(model_file)\n",
    "\n",
    "# Convert test data to DMatrix\n",
    "dtest = xgb.DMatrix(X_test)\n",
    "\n",
    "# Predict\n",
    "y_pred = booster.predict(dtest)\n",
    "\n",
    "y_pred[:4]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b429248-351a-4fc0-8df3-81185ed2b7c5",
   "metadata": {},
   "source": [
    "### Transition the Model to Production"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9ff2f557-4e63-4bd5-880b-ddea66ad860a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Successfully registered model 'anomaly-detection-prod'.\n",
      "Copied version '1' of model 'XGB-Smote' to version '1' of model 'anomaly-detection-prod'.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<ModelVersion: aliases=[], creation_timestamp=1766674468455, current_stage='None', deployment_job_state=<ModelVersionDeploymentJobState: current_task_name='', job_id='', job_state='DEPLOYMENT_JOB_CONNECTION_STATE_UNSPECIFIED', run_id='', run_state='DEPLOYMENT_JOB_RUN_STATE_UNSPECIFIED'>, description='', last_updated_timestamp=1766674468455, metrics=None, model_id=None, name='anomaly-detection-prod', params=None, run_id='640aa0b1aea4450f84eff29b8e1ad6cd', run_link='', source='models:/XGB-Smote/1', status='READY', status_message=None, tags={}, user_id='', version='1'>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_model_uri = f\"models:/{model_name}@challenger\"\n",
    "production_model_name = \"anomaly-detection-prod\"\n",
    "\n",
    "client = mlflow.MlflowClient()\n",
    "client.copy_model_version(src_model_uri=current_model_uri, dst_name=production_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2590713c-5925-4ebf-9bec-fa102f46c587",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9c54a2847364d4d9220df2da58abfbf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([0.00236887, 0.0019822 , 0.01328653, 0.000823  ], dtype=float32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import mlflow\n",
    "import xgboost as xgb\n",
    "import os\n",
    "\n",
    "# Download model artifacts\n",
    "local_path = mlflow.artifacts.download_artifacts(\n",
    "    artifact_uri=f\"models:/{production_model_name}@champion\" # /{model_version}\n",
    ")\n",
    "\n",
    "# Correct model file (from inspection)\n",
    "model_file = os.path.join(local_path, \"model.ubj\")\n",
    "\n",
    "# Load raw XGBoost booster\n",
    "booster = xgb.Booster()\n",
    "booster.load_model(model_file)\n",
    "\n",
    "# Convert test data to DMatrix\n",
    "dtest = xgb.DMatrix(X_test)\n",
    "\n",
    "# Predict\n",
    "y_pred = booster.predict(dtest)\n",
    "\n",
    "y_pred[:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a08b3ee-a3b6-41fa-b868-c57c5344534b",
   "metadata": {},
   "source": [
    "### Please use to the following link to learn more about model registry\n",
    "\n",
    "https://mlflow.org/docs/latest/model-registry.html#model-registry-workflows \n",
    "\n",
    "### to learn from the docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56337adb-2cc8-4ff5-a144-9dd3999933eb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
